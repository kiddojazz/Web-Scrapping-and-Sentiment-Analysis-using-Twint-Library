# Web Scrapping and Sentiment Analysis using Twint Library

Twitter is a social networking and news website where users exchange short messages known as tweets.
Twitter's main selling point is how easy it is to scan. Hundreds of interesting Twitter users can be followed and their information read at a glance, which is ideal in today's attention-deficit society.

Web scraping is becoming a household name for most data professionals all over the world. Web scraping is the process of extracting data from a website. This data is gathered and then exported into a format that is more user-friendly. Python libraries such as beautiful soup, selenium, and other Python libraries can assist with the web scraping process. 
For you to be able to use some of this library, you will need to have domain knowledge of HTML for you to easily navigate the site, which tends to be difficult for most data analysts.

The big question here is how can I scrape Twitter data without needing Twitter API, or having to create a Twitter developer account or domain knowledge of web development. 

The Twitter Developer account allows you to create and manage your own Projects and Apps with your developer account. This feature also comes with some limitations, that can be found in the Twitter FAQ session.

Look no further, Twint is a Python-based advanced Twitter scraping application that allows you to scrape Tweets from Twitter profiles without having to use Twitter's API.
Twint makes use of Twitter's search operators that allows you to scrape Tweets from specific individuals, scrape Tweets referring to specific themes, hashtags, and trends, and sort out sensitive information like e-mail and phone numbers from Tweets.

Twint also creates unique Twitter queries that allow you to scrape a Twitter user's followers, Tweets they've liked, and who they follow without having to utilize any login, API, Selenium, or browser emulation.

## Prerequisites
[Python](https://www.python.org/downloads/)

[aiohttp](https://pypi.org/project/aiohttp/)

[aiodns](https://pypi.org/project/aiodns/)

[beautifulsoup4](https://pypi.org/project/beautifulsoup4/)

[cchardet](https://pypi.org/project/cchardet/)

elasticsearch

[pysocks](https://pypi.org/project/PySocks/)

[pandas](https://pandas.pydata.org/docs/getting_started/install.html)

[aiohttp_socks](https://pypi.org/project/aiohttp-socks/)

[schedule](https://pypi.org/project/schedule/)

[geopy](https://pypi.org/project/geopy/)

[fake-useragent](https://pypi.org/project/fake-useragent/)

[py-googletransx](https://pypi.org/project/googletransx/)



## Benefits of using Twint
Only the last 3200 Tweets can be scraped using the Twitter API. Twint, on the other hand, can retrieve practically all Tweets.
Provides a variety of data sources to save your file i.e CSV, JSON, SQLite, and Elasticsearchd database.
Quick initial setup.
Can be used anonymously and without a Twitter account.
There are no rate restrictions.

## Installation
Twint can be installed with the pip command or straight from git. It is advisable you install Twint through git as it comes up with little or no issues.
